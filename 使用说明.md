# 项目整体结构

[cloudmusic_spider](#项目整体结构)	// workspace
		│	//  Ctrl + 单击 以跳转
		├─ [code](#code)
		│  ├─ [emo](#emo)
		│  │  ├─ [emo_score.py](#emo_score.py)
		│  │  ├─ [neg.txt](#neg.txt)
		│  │  ├─ [pos.txt](#pos.txt)
		│  │  └─ [sentiment.marshal.3](#sentiment.marshal.3)
		│  │
		│  ├─ [playlist](#playlist)
		│  │  ├─ [get_playlist_comments.py](#get_playlist_comments.py)
		│  │  └─ [get_playlist_info.py](#get_playlist_info.py)
		│  │
		│  ├─ [process](#process)
		│  │  ├─ [basic_filiter_xxl.py](#basic_filiter_xxl.py)
		│  │  ├─ [basic_filiter_yk.py](#basic_filiter_yk.py)
		│  │  ├─ [song_rec.py](#song_rec.py)
		│  │  ├─ [upload.py](#upload.py)
		│  │  ├─ [word_count.py](#word_count.py)
		│  │  ├─ [word_cut.py](#word_cut.py)
		│  │  └─ [word_cut_bak.py](#word_cut_bak.py)
		│  │
		│  ├─ [singer](#singer)
		│  │  └─ [get_singer_info.py](#get_singer_info.py)
		│  │
		│  ├─ [song](#song)
		│  │  ├─ [get_song_comments.py](#get_song_comments.py)
		│  │  ├─ [get_song_info.py](#get_song_info.py)
		│  │  ├─ [get_song_lyric.py](#get_song_lyric.py)
        │  │  └─ [get_song_tag.py](#get_song_tag.py)
        │  │
        │  ├─ [spider](#spider)
        │  │  └─ [Singles_chart.py](#Singles_chart.py)	// 爬虫入口
        │  │
        │  ├─ [tools](#tools)
        │  │  ├─ [comment.py](#comment.py)
        │  │  ├─ [file.py](#file.py)
        │  │  ├─ [post_params.py](#post_params.py)
        │  │  ├─ [progressBar.py](#progressBar.py)
        │  │  ├─ [request.py](#request.py)
        │  │  ├─ [sleep.py](#sleep.py)
        │  │  ├─ [stop_words.txt](#stop_words.txt)
        │  │  ├─ [struct.py](#struct.py)
        │  │  └─ [utils.py](#utils.py)
        │  │
        │  └─ [user](#user)
        │     ├─ [get_user_info.py](#get_user_info.py)
        │     ├─ [get_user_listen_rank.py](#get_user_listen_rank.py)
        │     └─ [get_user_playlist.py](#get_user_playlist.py)
        │
        ├─ [data](#data)	
        │  ├─ [info](#info)
        │  │  ├─ [playlist_info.txt](#playlist_info.txt)
        │  │  ├─ [singer_info.txt](#singer_info.txt)
        │  │  ├─ [song_info.txt](#song_info.txt)
        │  │  └─ [user_info.txt](#user_info.txt)
        │  │
        │  ├─ [playlist_comments](#playlist_comments)
        │  │  ├─ [playlist_3778678.txt](#playlist_3778678.txt)
        │  │  └─ ...
        │  │
        │  ├─ [rec](#rec)
        │  │  ├─ [rec_1904831431.txt](#rec_1904831431.txt)
        │  │  └─ ...
        │  │
        │  ├─ [song_comments](#song_comments)
        │  │  ├─ [song_1904831431.txt](#song_1904831431.txt)
		│  │  └─ ...
		│  │
		│  └─ [store](#store)
		│     ├─ [playlist_comment_emo.txt](#playlist_comment_emo.txt)
		│     └─ [song_comment_emo.txt](#playlist_comment_emo.txt)
		│
		└─ [README.md](#README.md)

# code

项目代码部分，爬虫入口位于[code/spider/Singles_chart.py](#Singles_chart.py)

## emo

本部分负责训练snownlp情感分析模型&计算各类emo指数

### emo_score.py

该文件负责借助snownlp分析歌词、评论、用户个性签名等一系列可能体现情感的语料，从而计算各类emo指数，具体如下：

- 一首歌的歌词emo指数
- 所有歌曲的歌词emo指数
- 单个评论文件的emo指数
- 所有评论文件的emo指数
- 单个歌曲的emo指数
- 所有歌曲的emo指数
- 单个用户的emo指数
- 所有用户的emo指数
- 单个歌手的emo指数
- 所有歌手的emo指数
- 单个歌单的emo指数
- 所有歌单的emo指数

以上各类emo指数均采用Spark、HDFS进行分析和存储

### neg.txt

用于训练snownlp情感分析模型的消极语料库，其中包含的用户评价emo程度较高

### pos.txt

用于训练snownlp情感分析模型的积极语料库，其中包含的用户评价emo程度较低

### sentiment.marshal.3

通过以上两个语料库训练得到的情感分析模型，可直接使用

在使用中，需要注意修改"**your_path_to_python**\Lib\site-packages\snownlp\sentiment\__init__.py"文件中的：

```python
data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          'sentiment.marshal')
```

==》'sentiment.marshal'改为本机上到本文件的绝对路径，但**不需要添加后缀".3"**，例如：

```python
data_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                          'E:/sentiment.marshal')
```



## playlist

负责歌单相关的信息爬取

### get_playlist_comments.py

负责爬取某一歌单下的评论信息，并返回参与评论的用户id列表以及评论总数

在运行过程中调用[tools](#tools)中的[comment.py](#comment.py)内的工具方法从json中提取相关信息，具体细节可跳转查看[Ctrl + 单击]

使用的歌单评论接口为：

```python
url = f'https://music.163.com/api/v1/resource/comments/A_PL_0_{playlistid}?limit=20&offset={page}'
```

数据爬取结束后暂存于本地的[data/playlist_comments](#playlist_comments)文件夹下，详细信息可跳转查看。

### get_playlist_info.py

负责爬取某一歌单的详细信息，并返回上榜歌曲的id列表。

爬取的信息包括:

- 歌单ID
- 歌单名称
- 播放量
- 收藏量
- 歌单描述
- 歌单标签
- 创建者ID
- 上榜歌曲ID列表
- 歌单收录音乐的数量
- 评论数

以上数据爬取结束后暂存于本地的[data/info/playlist_info.txt](#playlist_info.txt)中，详细信息可跳转查看。

## process

### basic_filiter_xxl.py

说明：对data目录下的原始数据进行清洗（方法一），存放在hdfs上的basic_data目录下，上下两个清洗脚本的区别体现在清洗评论文件，方法一是并行处理，适用于对每个文件操作较为简单的情况；方法二是遍历处理，适用于文件数量较少，单文件操作相对复杂的情况。

custom_function()函数：对单个评论文件对象进行清洗的操作

其他函数的功能与下面的`basic_filiter_yk.py`操作相同。



### basic_filiter_yk.py

说明：对data目录下的原始数据进行清洗（方法二），存放在hdfs上的basic_data目录下

函数功能：

- lyric_filter()函数：对歌词使用正则表达式进行过滤，过滤时间戳`[00:00.00]`和歌曲创作信息`作词 : 周杰伦`

- new_dir()函数：在hdfs上创建basic_data目录存放清洗后的数据，新建info、playlist_comments、song_comments目录分别存放信息文件、所有歌单评论文件、所有歌曲评论文件
- singer_info_filter()函数：对`data/info/singer_info.txt`文件中的歌手信息进行过滤，按照歌手ID去重，去除属性数不为5的记录
- playlist_info_filter()函数：对`data/info/playlist_info.txt`文件中的歌单信息进行过滤，按照歌单ID去重，去除属性数不为10的记录
- user_info_filter()函数：对`data/info/user_info.txt`文件中的用户信息进行过滤，按照用户ID去重，去除属性数不为11的记录，去除年龄不在指定范围内的记录
- song_info_filter()函数：对`data/info/song_info.txt`文件中的歌曲信息进行过滤，按照歌曲ID去重，去除属性数不为8的记录，去除歌曲歌词为空、并对第五列的歌词进行清洗操作
- comment_filter()函数：对`data/playlist_comments/`和`data/song_comments`目录下的所有评论文件进行清洗操作，由于一个用户可以连续发多条评论，所以评论不去重，去除属性数不为6和评论内容为空的记录

其中，对所有的评论文件进行清洗，遍历每一个评论文件生成的rdd执行上述清洗评论文件的操作。



### song_rec.py

负责相似歌曲推荐算法的实现，主要是结合歌曲本身和用户画像，从爬取的歌曲库中筛选出相似歌曲。

算法具体思路详见文档 	[推荐算法.md](推荐算法.md)	[Ctrl + 单击以跳转]

### upload.py

说明：上传本地爬取的原始数据到hdfs上的`/data/`目录下，前期没有发现hdfs的`hdfs -fs get`命令不仅可以上传文件还可以上传目录，但是该文件的上传速度和命令差不多，并且增加了进度条，可以实时看到上传速度。



### word_count.py

说明：对`word_cut.py`文件分词后的`/cut_data/`目录下的数据进行词频统计，生成词云.

函数功能：

- extract_words()函数：提取评论中的地区和单词。
- transform()函数：统计完每个地区的高频词汇后整理为一个元组(region, words, frequences)。
- province_word_count()函数：统计每个地区评论中的词频，先整合所有的评论为一个rdd，然后按照地区统计高频词汇，并且进行排序操作。
- playlist_word_count()函数：统计每个歌单评论中的词频。
- count_lyric()函数 + song_word_count()函数：统计每一首歌的歌词的词云。
- song_comment_wordcount()函数：统计每首歌的评论区词云。
- singer_word_count()函数：统计每个歌手创建歌曲时的高频词汇，需要先获取每个歌手对应创作的歌曲，然后结合所有其创作的歌曲，获得该歌手创作时高频的词汇。

根据以上函数的功能，可以实现地区评论词云、歌单评论词云、歌词词云、歌曲评论词云、歌手创作词云



### word_cut.py

说明：对用户的个人简介、歌曲的歌词、评论进行分词（方法一），并且存入新创建的`/cut_data/`目录下。

函数功能：

- stopwordslist()函数：手动在`/tools/stop_words.txt`中增加停用词、读取停用词，并且转换为集合，加快后续查找速度；	  
- jieba_addwords()函数：手动增加分词；
- depart()函数：对输入句子进行分词

以上三个函数，调用jieba分词库，实现分词功能。

- signature_cut()函数：对用户的个人简介进行分词
- lyric_cut()函数：对歌曲的歌词进行分词
- comment_cut()函数：对评论进行分词

其中，该函数对所有评论文件的清洗操作是并行进行的。



### word_cut_bak.py

说明：对用户的个人简介、歌曲的歌词、评论进行分词（方法二），并且存入新创建的`/cut_data/`目录下。

与方法一的区别是这个方法的处理方式是遍历所有评论文件的rdd进行分词。



## singer

### get_singer_info.py

## song

### get_song_comments.py

### get_song_info.py

### get_song_lyric.py

### get_song_tag.py

## spider

### Singles_chart.py

## tools

### comment.py

说明：处理请求获得的json格式的一页评论

- hotcomments()函数：从第一页的评论数据中提取出所有热评信息（评论用户ID、评论内容、评论地区等），并返回评论者的用户ID
- comments()函数：从评论数据中提取出所有评论信息，并返回评论者的用户ID
- 

### file.py

### post_params.py

### progressBar.py

### request.py

### sleep.py

### stop_words.txt

### struct.py

### utils.py

## user

### get_user_info.py

### get_user_listen_rank.py

### get_user_playlist.py

# data

项目数据部分，用于存储爬取到的数据

## info

### playlist_info.txt

### singer_info.txt

### song_info.txt

### user_info.txt

## playlist_comments

### playlist_3778678.txt

## rec

### rec_1904831431.txt

## song_comments

### song_1904831431.txt

## store

### playlist_comment_emo.txt

### playlist_comment_emo.txt

# README.md

项目说明文档
